{% extends "layout.html" %}

{% block body %}
<div class="container" width="800px">
    <div class="col-sm-12 col-md-12 col-lg-10 col-lg-offset-1">
        <div class="row" id="page-title">
            <div class="col-md-12">
                <h1>Flu Forecaster</h1>
            </div>
        </div>
        <div class="row" id="page-heading">
            <div class="col-md-6">
                <h4>Predicting influenza sequence evolution using deep learning.</h4>
                <img src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/eric-ma-headshot.jpg" alt="Eric J. Ma" style="clip-path: circle(75px at center); width: 150px; height: 150px; margin-left: auto; margin-right: auto; display: block;">
                <h1 style="text-align: center">
                    <a href="https://twitter.com/ericmjl"><i class="fa fa-twitter-square" aria-hidden="true"></i></a>
                    <a href="https://github.com/ericmjl"><i class="fa fa-github-square" aria-hidden="true"></i></a>
                    <a href="https://www.linkedin.com/in/ericmjl/"><i class="fa fa-linkedin-square" aria-hidden="true"></i></a>
                </h1>

                <p>by <a href="http://www.ericmjl.com/">Eric J. Ma</a>, Insight Health Data Science Fellow, Boston Summer Session 2017</p>
            </div>
            <div class="col-md-6">
                <iframe src="https://docs.google.com/presentation/d/1GHSUZHxxEATvhhffTnpjJIoKW65ZJ0NeQ3M4hh_fYzI/embed?start=false&loop=false&delayms=3000" frameborder="0" width="480" height="299" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
            </div>
        </div>
        <div class="row" id="summary-text">
            <div class="col-md-12">
                <h2>Summary</h2>
                <p>In this project, I combine the use of Variational Autoencoders (VAEs) and Gaussian Process (GP) regression to forecast what influenza protein sequences will look like six months ahead.</p>

                <p>In this project:</p>
                <ul>
                    <li>VAEs transform discrete sequence to a continuous representation.</li>
                    <li>We use GPs for time-series regression to forecast future continuous space representations of flu.</li>
                    <li>We then take the forecasted representations, and pass them back through the VAE to get back predicted sequences.</li>
                </ul>
                <p>Source code for this project can be found <a href="https://github.com/ericmjl/flu-sequence-predictor">on GitHub</a>.</p>

            </div>
        </div>
        <div class="row" id="predicted-sequences-row">
            <div class="col-md-12">
                <h2>Predicted Sequences</h2>
                <p>Given the current evolutionary trajectory of the influenza A virus, there are {{ n_seqs }} distinct predicted "average" influenza hemagglutinin sequences for the coming quarter.</p>
            </div>
        </div>
        <div class="row" id="multiple-sequence-alignment-row">

            <div class="col-md-12" id="multiple-sequence-alignment">
                <!-- Do not delete this set of divs. The relevant script is below to make the page load faster. -->
            </div>
        </div>
        <div class="row" id="summary-row">
            <div class="col-md-12" id="summary-text">
            </div>
        </div>
        <div class="row" id="problem-text-title">
            <div class="col-md-12" id="problem-title">
                <h2>Problem</h2>
            </div>
        </div>
        <div class="row" id="problem-text-row">
            <div class="col-md-8" id="problem-text">
                <p>Influenza vaccine strain selection lags behind deployment by about 6 months to 2 years, while production lags behind deployment by about 6 months. Additionally, vaccine strains are selected from amongst currently-circulating strains.</p>

                <p><b>This means that the flu virus will have evolved by the time the vaccine strain is scaled into production.</b></p>
            </div>
            <div class="col-md-4" id="fig-vaccine">
                <img src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/vaccine-production-sm.jpg" alt="Vaccine production lag time." width="100%">
                <p><i>Large lag time from vaccine strain selection to actual deployment.</i></p>
            </div>
        </div>
        <div class="row" id="problem-text-row-2">
            <div class="col-md-8" id="problem-text-business-opportunity">
                <p>There is a lost business opportunity here, as studies by the CDC are showing that <a href="https://www.cdc.gov/mmwr/volumes/66/wr/mm6606a3.htm?s_cid=mm6606a3_w">the 2017 vaccine efficacy is below 50%</a> on most years, with some years dropping to below 20% efficacy. Sustained lack of efficacy may result in a lack of public confidence in vaccination. The most immediate impact would be a contraction in the market for vaccines, followed by adverse impacts for public health. With a <a href="http://www.cnbc.com/2015/10/19/the-16-billion-business-of-flu.html">USD 4 billion dollars market size globally</a>, vaccine manufacturers cannot afford for public confidence to be eroded.</p>

                <p><b>Good science can help make vaccines that better match what will actually be circulating, which is good business sense, and that is the goal of this project.</b></p>
            </div>
            <div class="col-md-4" id="vaccine-effectiveness-plot">
                {{ ve_div|safe }}

                <!-- <p><i>Vaccine effectiveness has not historically been high. Data from the <a href="https://www.cdc.gov/flu/professionals/vaccination/effectiveness-studies.htm">CDC</a></i>.</p> -->
            </div>
        </div>
        <div class="row" id="data-title-row">
            <div class="col-md-12">
                <h2>Data</h2>
            </div>
        </div>
        <div class="row" id="data-text-row">
            <div class="col-md-8" id="data-source-text">
                <p>The data are sourced from the <a href="https://www.fludb.org/brc/home.spg?decorator=influenza">Influenza Research Database</a>, a publicly-hosted repository of influenza sequencing data. Each virus that is sequenced is geographically- and time-stamped. The data I collected span the years {{ nseq_metadata['min_year'] }}-{{  nseq_metadata['max_year'] }}. I only downloaded hemagglutinin (HA) protein sequence, because it is the protein most determinant of an immune response; <b>if the vaccine strain's HA sequence is similar to the circulating strain's HA sequence, then it will provide protection against the circulating strain</b>.</p>

                <p>There are multiple subtypes of influenza; some you may have heard include "H1N1", "H3N2" and "H5N1". I focused only on H3 hemagglutinin protein sequences sourced from human patients worldwide. In total, there are {{ nseq_metadata['n_seqs'] }} influenza sequences considered in the dataset.</p>
            </div>
            <div class="col-md-4" id="data-per-year-plot">
                {{ nseq_div|safe }}
                <!-- <p><i>Number of influenza sequences per year in the dataset used for Flu Forecaster.</i></p> -->
            </div>
        </div>
        <div class="row" id="analysis-methods-and-tools-header-row">
            <div class="col-md-12" id="analysis-methods-and-tools-header-container">
                <h2>Analysis Methods and Tools</h2>
                <img src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/overview-figure-slides-sm.jpg" alt="" width="100%">
            </div>
        </div>
        <div class="row" id="analysis-methods-titles">
            <div class="col-md-4" id="preprocessing-title-column">
                <h3>Data Preprocessing</h3>
            </div>
            <div class="col-md-4" id="vae-title-column">
                <h3>Variational Autoencoders</h3>
            </div>
            <div class="col-md-4" id="gp-title-column">
                <h3>Gaussian Process Regression</h3>
            </div>
        <div class="row" id="analysis-methods-and-tools-text-row">
            </div>
            <div class="col-md-4" id="preprocessing-text-column">
                <p>Sequences were padded with <code>*</code> (asterisk) characters to the maximal length. They were then one-hot-encoded at each position, yielding a sparse binary matrix representation of each protein's amino acid sequence. Of the 18 years of data used, 17 years (2000-2016) were part of the training set, and the final year (2017) was held out for forecasting validation.</p>

                <button type="button" name="learn-more-preprocessing" class="btn btn-primary" data-toggle="modal" data-target="#preprocessingModal">Learn More</button>

                <div class="modal fade" id="preprocessingModal" tabindex="-1" role="dialog" aria-labelledby="preprocessing-modal-title">
                    <div class="modal-dialog" role="document">
                        <div class="modal-content">
                            <div class="modal-header">
                                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                <h3 class="modal-title" id="preprocessing-modal-title"> Data Preprocessing</h3>
                            </div>
                            <div class="modal-body" id="modal-body-preprocessing">
                                <img class="img-responsive center-block" src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/preprocessing-figures-sm.jpg" alt="" width=80%>
                                <h4>Sequence Padding</h4>
                                <p>Contrary to what might be common thought, multiple sequence alignment was not done prior to conversion to a numerical form. Rather, I first computed the maximum sequence length represented inside the set of sequences downloaded, and padded <code>*</code> (asterisk) characters on each sequence until all of them fit that length. </p>

                                <p>This done using custom Python code and the <code>BioPython</code> and <code>numpy</code> packages.</p>

                                <h4>One-Hot Encoding</h4>
                                <p>Sequences were then one-hot encoded at each position. Memory was not an issue, and as such each amino acid position was converted into 24-long vector, with one slot in the vector per canonical amino acid, three more for ambiguous a.a. (B, J, X), and one for the padding character ("*"). Each vector slot represents an amino acid letter. A "1" is placed in a slot if the amino acid at the currently considered position corresponds to that slot's letter, and a "0" is placed everywhere else. </p>

                                <p>This was accomplished using the <code>sklearn.preprocessing</code> module.</p>

                                <h4>Validation Set</h4>

                                <p>In time series analysis, data cannot be held out at random. This is because there's potentially "autocorrelation structure" in time-series data - the value of a data point at time "x" may depend on the value of a data point at time "x-1".</p>

                                <p>For the sake of computational efficiency, I first downsampled sequences to their <b>mean sequence per quarter</b>, and performed time-series regression on this downsampled dataset. Improvements to this are addressed below the evolutionary trajectory plots.</p>

                                <p>Here, I held out the last two calendar quarters of data, corresponding to data from the first two quarters of the year 2017.</p>

                                <p>This done using custom Python code and the <code>pandas</code> package.</p>

                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-4" id="vae-text-column">
                <p>VAEs were used to learn a continuous latent embedding/representation of the binary encoded protein sequence on which a Gaussian Process regression model could be used for forecasting. It learns a generative model of sequence space, allowing us to sample new sequences out of forecasted latent space.</p>

                <button type="button" name="learn-more-vae" class="btn btn-primary" data-toggle="modal" data-target="#vaeModal">Learn More</button>

                <div class="modal fade" id="vaeModal" tabindex="-1" role="dialog" aria-labelledby="vae-modal-title">
                    <div class="modal-dialog" role="document">
                        <div class="modal-content">
                            <div class="modal-header">
                                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                <h3 class="modal-title" id="vae-modal-title">Variational Autoencoders</h3>
                            </div>
                            <div class="modal-body" id="modal-body-vae">
                                <img class="img-responsive center-block" src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/vae-icon.jpg" alt="" width="200px">
                                <p>Autoencoders reconstruct the input as the output, and simultaneously learn a lower-dimensional "latent" representation of the original data. With sequences, this has the advantage of converting a "discrete" input into a "continuous" one; with continuous representations, we have a wealth of regression methods that can be used that would not otherwise be available using protein sequences. The encoder portion of the network compresses the data to the latent embedding, and the decoder network reconstructs sequences from latent embedding coordinates.</p>

                                <p>"Variational" autoencoders learn not just the "point estimate" in "latent embedding space", but also the probability distribution in "latent embedding space" that corresponds to a particular sequence. This means that we can also sample new sequences out of the latent space, and generate new, unseen sequences. This gives us hope for forecasting what new sequences will look like.</p>

                                <p>Here, after converting the sequences to a binary encoding, I passed the binary-encoded matrix through a VAE to learn a 3D embedding, which you can visualize below.</p>

                                <p><b>Basically</b>, VAEs give us a convenient representation of sequence space that lets us do other machine learning on it.</p>

                                <p>Variational Autoencoders were implemented using the <code>Keras</code> package.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-md-4" id="gp-text-column">

                <p>Gaussian Processes were used to forecast the latent embedding coordinates for future influenza sequences. The forecasted coordinates were passed back to the decoder portion of the VAE to provide the probability distribution over possible sequences.</p>

                <button type="button" name="learn-more-gp" class="btn btn-primary" data-toggle="modal" data-target="#gpModal">Learn More</button>

                <div class="modal fade" id="gpModal" tabindex="-1" role="dialog" aria-labelledby="gp-modal-title">
                    <div class="modal-dialog" role="document">
                        <div class="modal-content">
                            <div class="modal-header">
                                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                                <h3 class="modal-title" id="gp-modal-title">Gaussian Process Regression</h3>
                            </div>
                            <div class="modal-body" id="modal-body-gp">
                                <!-- <h4>Gaussian Processes (GPs)</h4> -->
                                <img class="img-responsive center-block" width="300px" src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/gp-icon-sm.jpg" alt="">
                                <p>Gaussian Processes are a "lazy" and Bayesian machine learning method well suited to learning non-linear functions of data. The basic idea behind GPs is as such: given a set of data points sampled from a non-linear function, it will return a probability distribution over the possible functions that fit the dataset. GPs are called "lazy" because they assume that points nearby one another on one axis will be nearby one another on the other axis.</p>

                                <p>In time-series land, GPs are particularly useful because time-series data may be varying in a non-linear fashion with time (think stock markets), and they are able to provide quantified estimates of <b>uncertainty</b> in predictions (because they're Bayesian - Go Bayes!).</p>

                                <p><b>Basically</b>, GPs provide a way of quantifying the uncertainty surrounding predicted sequences.</p>

                                <p>GPs here were implemented using <code>PyMC3</code>.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="row" id="evoluiontary-trajectory-title-row">
            <div class="col-md-12" id="evolutionary-trajectory-text">
                <h2>Evolutionary Trajectory</h2>
                <p>Read on to see how to interpret the scatter plots below.</p>
            </div>
        </div>
        <div class="row" id="evolutionary-trajectory-text-row">
            <div class="col-md-6" id="time-varying-evolution-text">
                <h3>Time-varying Evolution</h3>
                <p>Using a variational autoencoder, we can visualize the evolutionary trajectory of viral proteins in lower dimensions. In Flu Forecaster, I have chosen to visualize them in 3 dimensions. Because 3D visualizations are difficult in the browser, I have decomposed the plots to show pairs of dimensions at a time.</p>
                <p>Each point in the scatterplot below is a representation of the "median" flu sequence per calendar quarter. The points are coloured by time - dark colours are earlier (starting at the year 2000), and light colours are later (ending at the year 2016).</p>
                <img src="https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/images/scatter-colorbar-sm.jpg" alt="" width=100%>
            </div>
            <div class="col-md-6" id="forecasted-sequences-text">
                <h3>Forecasted Sequences</h3>
                <p>Forecasted sequences are visualized using <b>bounding boxes</b>. Each bounding box represents one sequence, and they are coloured differently. In 3D space, each unique sequence takes up a "volume"; sequences with larger "volumes" (or areas in the 2D projection) have larger forecasted probability of showing up. The uncertainty in the forecasts are thus represented by the <b>probability distribution over possible discrete sequences</b>. In other words, we don't forecast one sequence, but a set of sequences. For visual simiplicity, only those sequences with a greater than 2.5% probability of showing up are shown.</p>
            </div>
        </div>
        <div class="row" id="evolutionary-trajectory-plots-row">
            <div class="col-md-12 center-block" id="evolutionary-trajectory-plot">
                {{ evo_div|indent(4)|safe }}
            </div>
        </div>
        <div class="row" id="improvements-text-row">
            <div class="col-md-12">
                <h2>Improvements</h2>
                <p>Data-driven science is never really done. Here's how I think this project can be taken to the next level.</p>
            </div>
        </div>
        <div class="row" id="improvements-explanation-row">
            <div class="col-md-4" id="forecasting-diversity-text">
                <h3>Forecasting Diversity</h3>
                <p>Right now, Flu Forecaster predicts forecasted sequences one quarter out, and only predicts the "median sequence" that we expect to see. This "median" sequence actually differs from other-circulating viruses by anywhere from 6-19 amino acids, and the other protein sequences represent the diversity/variance of amino acid sequences possible. In order to accomplish this, I would have to train both the mean and the variance in each coordinate dimension, and jointly sample coordinates using both the mean and variance.</p>
            </div>
            <div class="col-md-4" id="gp-training-text">
                <h3>GP Training</h3>
                <p>The Gaussian Process coordinate dimensions are trained independently. It may be better to train the GP on all 3 dimensions jointly, though experimentation would be needed to determine whether increased computational complexity would be worth the accuracy.</p>
            </div>
            <div class="col-md-4" id="validation-text">
                <h3>Validation</h3>
                <p>More work needs to be done on backtesting. Currently, I am doing model validation by checking that the 2017 "average" coordinates fall within the 95% HPD of the latent space coordinates. I have yet to perform more periods of backtesting, in which I hold out more than just two quarters of data.</p>
            </div>
        </div>
        <div class="row" id="conclusions-row">
            <div class="col-md-12">
                <h2>Conclusions</h2>
                <p>Forecasting how sequences evolve is a tough problem, primarily because there's no notion of "forward momentum" when talking about changes in sequence land. However, if we transform the problem into one involving a "continuous" representation, we can take advantage of concepts like momentum vectors and gradients, and harness tools from continuous time-series regression.</p>
            </div>
        </div>
        <div class="row" id="about-row">
            <div class="col-md-12" id="about-author-text">
                <hr>
                <h4>Author Info</h4>
                <p>Eric obtained his ScD (Doctor of Science) degree from the Department of Biological Engineering at MIT in 2017. He is an avid open source fan, and believes in the Bassist's philosophy: do important work and pace the teamÂ behind the scenes, and step up front only when necessary. His personal website can be found at <a href="http://www.ericmjl.com">www.ericmjl.com</a>.</p>
            </div>
        </div>
        <div class="row" id="hr-row">
            <div class="col-md-12" id="hr-col">
                <hr>
            </div>
        </div>
    </div>
</div>

<!-- JS Scripts -->
<!-- Multiple sequence alignment scripts -->
<script src="https://s3.eu-central-1.amazonaws.com/cdn.bio.sh/msa/latest/msa.min.gz.js"></script>
<script>
    var opts = {
        el: document.getElementById("multiple-sequence-alignment"),
        vis: {
          conserv: true,
          overviewbox: false,
          seqlogo: true,
        },
        colorscheme: {
          scheme: "clustal2"
        },
        // smaller menu for JSBin
        // menu: "small",
        // bootstrapMenu: true,
        importURL: "https://raw.githubusercontent.com/ericmjl/flu-sequence-predictor/master/data/twoQ_predictions.fasta",
    };

    var m = new msa.msa(opts);
        m.render();

</script>

<!-- FontAwesome -->
<script src="https://use.fontawesome.com/cb9dbe8e41.js"></script>


<!-- Bokeh JS -->
{{ js_resources|indent(4)|safe }}
{{ css_resources|indent(4)|safe }}
<!-- Bokeh Plots -->
{{ evo_script|indent(4)|safe }}
{{ nseq_script|safe }}
{{ ve_script|safe }}
{% endblock %}
